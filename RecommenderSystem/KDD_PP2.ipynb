{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the original DataFrame: 100836\n",
      "Number of rows in the sampled DataFrame: 40334\n",
      "Number of rows in the filtered DataFrame: 21928\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data - Sampling\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "ratings_csv = pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\KDD_PP2\\\\ml-latest-small\\\\ratings.csv')\n",
    "\n",
    "# Perform sampling\n",
    "sampled_df = ratings_csv.sample(frac=0.4, replace=False, random_state=42)\n",
    "\n",
    "print(\"Number of rows in the original DataFrame:\", ratings_csv.shape[0])\n",
    "print(\"Number of rows in the sampled DataFrame:\", sampled_df.shape[0])\n",
    "\n",
    "\n",
    "# Preprocessing data - Remove users and movies that have less than 12 ratings\n",
    "\n",
    "while True:\n",
    "    # Group ratings by userId and movieId, then count the ratings for each user and movie\n",
    "    user_ratings_count = sampled_df.groupby('userId').size()\n",
    "    movie_ratings_count = sampled_df.groupby('movieId').size()\n",
    "\n",
    "    # Filter users and movies with less than 12 ratings each\n",
    "    filtered_users = user_ratings_count[user_ratings_count >= 12].index\n",
    "    filtered_movies = movie_ratings_count[movie_ratings_count >= 12].index\n",
    "    filtered_ratings = sampled_df[(sampled_df['userId'].isin(filtered_users)) & (sampled_df['movieId'].isin(filtered_movies))]\n",
    "\n",
    "    # Group ratings by userId and movieId, then count the ratings for each user and movie\n",
    "    f_user_ratings_count = filtered_ratings.groupby('userId').size()\n",
    "    f_movie_ratings_count = filtered_ratings.groupby('movieId').size()\n",
    "\n",
    "    # Find users and movies with less than 12 ratings after filtering\n",
    "    users_with_less_than_12_ratings = f_user_ratings_count[f_user_ratings_count < 12].index\n",
    "    movies_with_less_than_12_ratings = f_movie_ratings_count[f_movie_ratings_count < 12].index\n",
    "\n",
    "    # If there are users or movies with less than 12 ratings, continue filtering\n",
    "    if not users_with_less_than_12_ratings.empty or not movies_with_less_than_12_ratings.empty:\n",
    "        sampled_df = filtered_ratings[~filtered_ratings['userId'].isin(users_with_less_than_12_ratings)]\n",
    "        sampled_df = sampled_df[~sampled_df['movieId'].isin(movies_with_less_than_12_ratings)]\n",
    "    else:\n",
    "        break  # Exit the loop if there are no users or movies with less than 12 ratings\n",
    "\n",
    "print(\"Number of rows in the filtered DataFrame:\", filtered_ratings.shape[0])\n",
    "# Remove the column 'timestamp'\n",
    "filtered_ratings = filtered_ratings.drop(columns=['timestamp'])\n",
    "filtered_ratings.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\KDD_PP2\\\\ml-latest-small\\\\filtered_ratings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Auxiliary functions to find N similar movies\n",
    "\n",
    "# The following function returns a list of movies that the specified user has rated.\n",
    "def get_user_rated_movies(userId,data):\n",
    "    # Filter ratings for the specified user\n",
    "    user_ratings = data[data['userId'] == userId]\n",
    "\n",
    "    # Get the movies that the user has rated\n",
    "    user_rated_movies = user_ratings['movieId'].tolist()\n",
    "\n",
    "    return user_rated_movies\n",
    "\n",
    "\n",
    "# The following function returns a user-movie matrix with ratings as values, where the columns correspond to \n",
    "# the movies in the provided list, with an optional extra column for a specific movie.\n",
    "def get_user_movie_matrix(user_rated_movies, data, extra_movie_id=None):\n",
    "    # Filter ratings for the movies in the list\n",
    "    filtered_ratings = data[data['movieId'].isin(user_rated_movies)]\n",
    "\n",
    "    # Pivot the DataFrame to get a user-movie matrix\n",
    "    user_movie_matrix = filtered_ratings.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "    # Append an extra column for the specified movie\n",
    "    if extra_movie_id is not None:\n",
    "        # Fetch ratings for the specified movie from the original ratings DataFrame\n",
    "        extra_movie_ratings = filtered_ratings[filtered_ratings['movieId'] == extra_movie_id].set_index('userId')['rating']\n",
    "    \n",
    "        # Append the extra movie column to the user-movie matrix\n",
    "        user_movie_matrix[extra_movie_id] = user_movie_matrix.index.map(extra_movie_ratings).fillna(0)\n",
    "\n",
    "    return user_movie_matrix\n",
    "\n",
    "\n",
    "# The following function calculates the adjusted cosine similarity for columns (movies) in a user-movie matrix.\n",
    "# It is analogous to Pearson correlation, but specifically designed for collaborative filtering of movies.\n",
    "# Given a movieId, it computes the similarity scores between that movie and all others in the matrix.\n",
    "def adjusted_cosine_similarity_for_movie(matrix, movie_id):\n",
    "    # Subtract the mean of each row from each element in the row\n",
    "    adjusted_matrix = matrix.sub(matrix.mean(axis=1), axis=0).fillna(0)\n",
    "\n",
    "    # Extract the column corresponding to the provided movieId\n",
    "    movie_column = adjusted_matrix[movie_id].values.reshape(1, -1)\n",
    "\n",
    "    # Calculate cosine similarity of the extracted column with all other columns\n",
    "    similarity_vector = cosine_similarity(movie_column, adjusted_matrix.T)\n",
    "\n",
    "    # Create a DataFrame with movieIds and their similarity scores\n",
    "    similarity_df = pd.DataFrame({\n",
    "        'movieId': adjusted_matrix.columns,\n",
    "        'similarity': similarity_vector.flatten()\n",
    "    })\n",
    "\n",
    "    return similarity_df\n",
    "\n",
    "\n",
    "# This function takes the number of desired similar movies (N), a movieId, and a DataFrame containing movie\n",
    "# similarities. It returns the top N most similar movies to the given movieId based on similarity scores.\n",
    "def find_similar_movies(N, movie_id, movie_similarity_df):\n",
    "    # Exclude the movie itself from the list of most similar movies\n",
    "    similar_movies = movie_similarity_df[movie_similarity_df['movieId'] != movie_id]\n",
    "\n",
    "    # Sort the movies based on similarity in descending order\n",
    "    similar_movies = similar_movies.sort_values(by='similarity', ascending=False)\n",
    "    \n",
    "    # Get the top N most similar movies\n",
    "    top_similar_movies = similar_movies.head(N).copy()  # Create a copy of the DataFrame\n",
    "    \n",
    "    return top_similar_movies\n",
    "\n",
    "\n",
    "# The following function takes a DataFrame of top N similar movies with their similarity scores and a userId. \n",
    "# It returns a dataframe that contains movieIds, similarities and the ratings given by the user for those movies.\n",
    "def find_user_ratings(similar_movies_df, data, userId):\n",
    "    # Merge the similar_movies_df with ratings to get the movieId, similarity, and rating information\n",
    "    merged_df = pd.merge(similar_movies_df, data[data['userId'] == userId], on='movieId')\n",
    "    \n",
    "    # Drop the userId column\n",
    "    merged_df = merged_df.drop(columns='userId')\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions to predict a rating\n",
    "\n",
    "# The following function calculates the mean rating given by a specific user.\n",
    "def calculate_user_mean_rating(userId, data):\n",
    "    # Filter ratings for the specified user\n",
    "    user_ratings = data[data['userId'] == userId]\n",
    "\n",
    "    # Calculate the mean rating for the user\n",
    "    user_mean_rating = user_ratings['rating'].mean()\n",
    "\n",
    "    return user_mean_rating\n",
    "\n",
    "\n",
    "# The following function calculates the mean rating of a specific movie.\n",
    "def calculate_movie_mean_rating(movieId, data):\n",
    "    # Filter ratings for the specified movie\n",
    "    movie_ratings = data[data['movieId'] == movieId]\n",
    "\n",
    "    # Calculate the mean rating for the movie\n",
    "    movie_mean_rating = movie_ratings['rating'].mean()\n",
    "\n",
    "    return movie_mean_rating\n",
    "\n",
    "\n",
    "# The following function adds a 'bias removal' column to the DataFrame containing similarity scores, movieIds, and ratings.\n",
    "def add_bias_removal_column(similarity_df, data):\n",
    "    # Make a copy of the input DataFrame\n",
    "    similar_movies_copy = similarity_df.copy()\n",
    "    \n",
    "    # Calculate mean rating for each movie\n",
    "    similar_movies_copy['mean_rating'] = similar_movies_copy['movieId'].apply(lambda x: calculate_movie_mean_rating(x, data))\n",
    "\n",
    "    # Calculate 'bias removal' for each row\n",
    "    similar_movies_copy['bias_removal'] = similar_movies_copy['rating'] - similar_movies_copy['mean_rating']\n",
    "\n",
    "    return similar_movies_copy\n",
    "    \n",
    "\n",
    "# Calculate the weighted mean rating with bias adjustment\n",
    "def weighted_mean_rating_2(data, similar_movies_df, userId, movieId):\n",
    "    weighted_mean = calculate_user_mean_rating(userId, data) + ((similar_movies_df['similarity'] * \\\n",
    "    similar_movies_df['bias_removal']).sum() / similar_movies_df['similarity'].sum())\n",
    "    \n",
    "    return weighted_mean\n",
    "\n",
    "\n",
    "# Adds a 'common_users_weight' column to the similarity dataframe, representing the weight based on the number\n",
    "# of common users between the provided movie_id and each row in similarity dataframe. Common users are adjusted\n",
    "# by adding 1 to ensure a minimum weight of 1 for all movies.\n",
    "#def add_weighted_common_users_column(movie_id, similarity_df, data):\n",
    "    # Extract the users who have rated the provided movie_id\n",
    "#    users_movie_id = data[data['movieId'] == movie_id]['userId'].tolist()\n",
    "\n",
    "    # Make a copy of the input DataFrame\n",
    "#    similar_movies_copy = similarity_df.copy()\n",
    "    \n",
    "    # Calculate common users and assign weights based on the number of common users\n",
    "#    similar_movies_copy['common_users'] = similar_movies_copy.apply(\n",
    "#        lambda row: len(set(users_movie_id) & set(data[data['movieId'] == row['movieId']]['userId'].tolist())),\n",
    "#        axis=1\n",
    "#    )\n",
    "\n",
    "    # Add 1 to all common users and calculate weights based on the adjusted common users\n",
    "#    similar_movies_copy['common_users_weight'] = (similar_movies_copy['common_users'] + 1)\\\n",
    "#    / (similar_movies_copy['common_users'].max() + 1)\n",
    "\n",
    "#    return similar_movies_copy\n",
    "\n",
    "\n",
    "# [0.9,1]\n",
    "\n",
    "# Adds a 'common_users_weight' column to the similarity dataframe, representing the weight based on the number\n",
    "# of common users between the provided movie_id and each row in similarity dataframe. Common users are adjusted\n",
    "# by adding 1 to ensure a minimum weight of 1 for all movies.\n",
    "def add_weighted_common_users_column(movie_id, similarity_df, data):\n",
    "    # Extract the users who have rated the provided movie_id\n",
    "    users_movie_id = data[data['movieId'] == movie_id]['userId'].tolist()\n",
    "\n",
    "    # Make a copy of the input DataFrame\n",
    "    similar_movies_copy = similarity_df.copy()\n",
    "    \n",
    "    # Calculate common users and assign weights based on the number of common users\n",
    "    similar_movies_copy['common_users'] = similar_movies_copy.apply(\n",
    "        lambda row: len(set(users_movie_id) & set(data[data['movieId'] == row['movieId']]['userId'].tolist())),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Add 1 to all common users and calculate weights based on the adjusted common users\n",
    "    max_common_users_weight = similar_movies_copy['common_users'].max() + 1\n",
    "    similar_movies_copy['common_users_weight'] = (similar_movies_copy['common_users'] + 1) / max_common_users_weight\n",
    "    \n",
    "    # Ensure weights fall between 0.9 and 1\n",
    "    min_weight = 0.9\n",
    "    max_weight = 1\n",
    "    similar_movies_copy['common_users_weight'] = similar_movies_copy['common_users_weight'] *\\\n",
    "    (max_weight - min_weight) + min_weight\n",
    "\n",
    "    return similar_movies_copy\n",
    "\n",
    "\n",
    "# Calculate the weighted mean using similarity, rating, and common_users_weight\n",
    "def weighted_mean_rating_common_users(similarity_df):\n",
    "    weighted_sum = (similarity_df['similarity'] * similarity_df['rating'] * similarity_df['common_users_weight']).sum()\n",
    "    total_weight = (similarity_df['similarity'] * similarity_df['common_users_weight']).sum()\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if total_weight == 0:\n",
    "        return None\n",
    "\n",
    "    # Calculate the rating\n",
    "    rating = weighted_sum / total_weight\n",
    "\n",
    "    return rating\n",
    "\n",
    "\n",
    "# Adds a 'variance' column to the similarity dataframe, representing the variance of ratings for each movie\n",
    "#def calculate_movie_variances(similarity_df,data):\n",
    "    # Make a copy of the input DataFrame\n",
    "#    similar_movies_copy = similarity_df.copy()\n",
    "    \n",
    "    # Group ratings by movieId and calculate variance for each movie\n",
    "#    movie_variances = data.groupby('movieId')['rating'].var().reset_index()\n",
    "#    movie_variances.columns = ['movieId', 'variance']\n",
    "    \n",
    "    # Merge with the similarity_df\n",
    "#    similar_movies_copy = pd.merge(similar_movies_copy, movie_variances, on='movieId', how='left')\n",
    "   \n",
    "#    return similar_movies_copy\n",
    "\n",
    "\n",
    "# [0.8, 1]\n",
    "\n",
    "# Adds a 'variance' column to the similarity dataframe, representing the variance of ratings for each movie\n",
    "def calculate_movie_variances(similarity_df, data):\n",
    "    # Make a copy of the input DataFrame\n",
    "    similar_movies_copy = similarity_df.copy()\n",
    "    \n",
    "    # Group ratings by movieId and calculate variance for each movie\n",
    "    movie_variances = data.groupby('movieId')['rating'].var().reset_index()\n",
    "    \n",
    "    # Logarithm of variance\n",
    "    movie_variances['variance_weight'] = np.log(movie_variances['rating'] + 1)\n",
    "    # Normalize variance\n",
    "    movie_variances['variance_weight'] = (movie_variances['variance_weight'] - movie_variances['variance_weight'].min()) / \\\n",
    "                                  (movie_variances['variance_weight'].max() - movie_variances['variance_weight'].min())\n",
    "    \n",
    "    # Adjust variance column in [0.8, 1]\n",
    "    movie_variances['variance_weight'] = 0.2 * movie_variances['variance_weight'] + 0.8\n",
    "    movie_variances = movie_variances.drop(columns=['rating'])\n",
    "\n",
    "    # Merge with the similarity_df\n",
    "    similar_movies_copy = pd.merge(similar_movies_copy, movie_variances, on='movieId', how='left')\n",
    "   \n",
    "    return similar_movies_copy\n",
    "\n",
    "\n",
    "def weighted_mean_rating_variance(similarity_df):\n",
    "    # Calculate the total weight as the sum of weighted variances\n",
    "    total_weight = (similarity_df['similarity'] * similarity_df['variance_weight']).sum()\n",
    "\n",
    "    # Calculate the prediction using the weighted mean with variance\n",
    "    prediction = (similarity_df['similarity'] * similarity_df['variance_weight'] * similarity_df['rating']).sum() / total_weight\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the top N similar movies for a given user and movie\n",
    "def find_similar_movies_for_movie(data, userId, movieId, N):\n",
    "    # Get the user-movie matrix with all the movies that the specified user has rated, \n",
    "    # plus the movie we want to predict its rating\n",
    "    user_rated_movies = get_user_rated_movies(userId, data)\n",
    "    user_movie_matrix = get_user_movie_matrix(user_rated_movies, data, movieId)\n",
    "    \n",
    "    # Calculate adjusted cosine similarity for the specified movie\n",
    "    movie_similarity_df = adjusted_cosine_similarity_for_movie(user_movie_matrix, movieId)\n",
    "    \n",
    "    # Find the top N similar movies for the specified user and movie\n",
    "    similar_movies = find_similar_movies(N, movieId, movie_similarity_df)\n",
    "    \n",
    "    # Get the specified users ratings for the similar movies\n",
    "    similar_movies = find_user_ratings(similar_movies, data, userId)\n",
    "    \n",
    "    return similar_movies\n",
    "\n",
    "\n",
    "# Adjust the calculated weighted mean rating to ensure it does not exceed the maximum rating of 5.0\n",
    "# or fall below the minimum rating of 0.5\n",
    "def adjust_rating(rating):\n",
    "    if((rating < -1) or (rating > 6.5)):\n",
    "        print(\"rating out of bounds: \", rating)\n",
    "        \n",
    "    if rating > 5.0:\n",
    "        return 5.0\n",
    "    elif rating < 0.5:\n",
    "        return 0.5\n",
    "    # If the rating is within bounds, return it unchanged\n",
    "    else:\n",
    "        return rating\n",
    "\n",
    "\n",
    "# Prediction Function 1\n",
    "\n",
    "# The following function calculates the weighted mean rating for a target movie using its N nearest neighbors.\n",
    "#def predict_weighted_mean_rating(similar_movies_df):\n",
    "#    # Calculate the weighted mean rating\n",
    "#    weighted_mean = (similar_movies_df['similarity'] * similar_movies_df['rating']).sum()\\\n",
    "#    / similar_movies_df['similarity'].sum()\n",
    "    \n",
    "#    weighted_mean = adjust_rating(weighted_mean)\n",
    "#    return weighted_mean\n",
    "\n",
    "\n",
    "# Prediction Function 1 (sim>0)\n",
    "\n",
    "# The following function calculates the weighted mean rating for a target movie using its N nearest neighbors.\n",
    "#def predict_weighted_mean_rating(similar_movies_df):\n",
    "def predict_weighted_mean_rating(similar_movies_df):\n",
    "    # Filter out rows with similarity less than 0\n",
    "    similar_movies_df = similar_movies_df[similar_movies_df['similarity'] > 0]\n",
    "    \n",
    "    # Check if there are any rows left after filtering\n",
    "    if similar_movies_df.empty:\n",
    "        print(\"rating out of bounds: 0\")\n",
    "        return 0  # Return 0 if there are no rows with positive similarity\n",
    "    \n",
    "    # Calculate the weighted mean rating\n",
    "    weighted_mean = (similar_movies_df['similarity'] * similar_movies_df['rating']).sum()\\\n",
    "    / similar_movies_df['similarity'].sum()\n",
    "    \n",
    "    # Adjust the rating if necessary\n",
    "    weighted_mean = adjust_rating(weighted_mean)\n",
    "    \n",
    "    return weighted_mean\n",
    "\n",
    "\n",
    "# Prediction Function 2 (sim>0)\n",
    "\n",
    "# The following function predicts the rating for a movie using a weighted mean approach with user bias adjustment.\n",
    "def predict_weighted_mean_rating_2(data, similar_movies, userId, movieId):\n",
    "    # Filter out rows with similarity less than 0\n",
    "    similar_movies = similar_movies[similar_movies['similarity'] > 0]\n",
    "    \n",
    "    # Check if there are any rows left after filtering\n",
    "    if similar_movies.empty:\n",
    "        print(\"rating out of bounds: 0\")\n",
    "        return 0  # Return 0 if there are no rows with positive similarity\n",
    "    \n",
    "    similar_movies_bias = add_bias_removal_column(similar_movies, data)\n",
    "    weighted_mean_2 = weighted_mean_rating_2(data, similar_movies_bias, userId, movieId)\n",
    "    \n",
    "    weighted_mean_2 = adjust_rating(weighted_mean_2)\n",
    "    \n",
    "    return weighted_mean_2\n",
    "\n",
    "\n",
    "# Prediction Function 3 (sim>0)\n",
    "\n",
    "# The following function predicts the rating for a movie using a weighted mean based on common users with similar movies.\n",
    "def predict_weighted_mean_rating_common_users(data, similar_movies, movieId):\n",
    "    # Filter out rows with similarity less than 0\n",
    "    similar_movies = similar_movies[similar_movies['similarity'] > 0]\n",
    "    \n",
    "    # Check if there are any rows left after filtering\n",
    "    if similar_movies.empty:\n",
    "        print(\"rating out of bounds: 0\")\n",
    "        return 0  # Return 0 if there are no rows with positive similarity\n",
    "    \n",
    "    similar_movies_common_users = add_weighted_common_users_column(movieId, similar_movies, data)\n",
    "    weighted_mean_3 = weighted_mean_rating_common_users(similar_movies_common_users)\n",
    "    \n",
    "    weighted_mean_3 = adjust_rating(weighted_mean_3)\n",
    "    \n",
    "    return weighted_mean_3\n",
    "\n",
    "\n",
    "# Prediction Function 4 (sim>0)\n",
    "\n",
    "# Calculate the prediction using a weighted mean with variance, where weights are based on the similarity and variance.\n",
    "def predict_weighted_mean_rating_variance(data, similar_movies):\n",
    "    # Filter out rows with similarity less than 0\n",
    "    similar_movies = similar_movies[similar_movies['similarity'] > 0]\n",
    "    \n",
    "    # Check if there are any rows left after filtering\n",
    "    if similar_movies.empty:\n",
    "        print(\"rating out of bounds: 0\")\n",
    "        return 0  # Return 0 if there are no rows with positive similarity\n",
    "    \n",
    "    similar_movies_variances = calculate_movie_variances(similar_movies,data)\n",
    "    weighted_mean_4 = weighted_mean_rating_variance(similar_movies_variances)\n",
    "    \n",
    "    weighted_mean_4 = adjust_rating(weighted_mean_4)\n",
    "    \n",
    "    \n",
    "    return weighted_mean_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts the rating for a given movie (movieId).\n",
    "# It finds the top N similar movies, then employs four different prediction methods:\n",
    "# 1. Weighted Mean Rating\n",
    "# 2. Weighted Mean Rating with Adjustment and Bias Removal\n",
    "# 3. Weighted Mean Rating with Common Users\n",
    "# 4. Weighted Mean Rating with Variance\n",
    "def predict_ratings(data, userId, movieId, N, method):\n",
    "    # Step 1: Find top N similar movies with movie movieId\n",
    "    similar = find_similar_movies_for_movie(data, userId, movieId, N)\n",
    "    \n",
    "    # Step 2: Predict the rating of the movie movieId\n",
    "    # Call the prediction function based on the method\n",
    "    if method == 1:\n",
    "        prediction = predict_weighted_mean_rating(similar)\n",
    "    elif method == 2:\n",
    "        prediction = predict_weighted_mean_rating_2(data, similar, userId, movieId)\n",
    "    elif method == 3:\n",
    "        prediction = predict_weighted_mean_rating_common_users(data, similar, movieId)\n",
    "    elif method == 4:\n",
    "        prediction = predict_weighted_mean_rating_variance(data, similar)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7851dc1dc76b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;31m# Run the experiments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_experiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;31m# Print the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-7851dc1dc76b>\u001b[0m in \u001b[0;36mrun_experiments\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[1;31m# Run predictions and evaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0mmae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0mmae_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmae\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-7851dc1dc76b>\u001b[0m in \u001b[0;36mevaluate_predictions\u001b[1;34m(train_data, test_data, N, method)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# Call the prediction function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_ratings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserId\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovieId\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;31m# Calculate the error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-732a7bfa8b05>\u001b[0m in \u001b[0;36mpredict_ratings\u001b[1;34m(data, userId, movieId, N, method)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_ratings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserId\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovieId\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Step 1: Find top N similar movies with movie movieId\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0msimilar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_similar_movies_for_movie\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserId\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovieId\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Step 2: Predict the rating of the movie movieId\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-31185576d8c2>\u001b[0m in \u001b[0;36mfind_similar_movies_for_movie\u001b[1;34m(data, userId, movieId, N)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Get the user-movie matrix with all the movies that the specified user has rated,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# plus the movie we want to predict its rating\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0muser_rated_movies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_user_rated_movies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muserId\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0muser_movie_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_user_movie_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_rated_movies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovieId\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-1438045f8b14>\u001b[0m in \u001b[0;36mget_user_rated_movies\u001b[1;34m(userId, data)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_user_rated_movies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muserId\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Filter ratings for the specified user\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0muser_ratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'userId'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0muserId\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Get the movies that the user has rated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomparison_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m                 \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_arithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0muse_numexpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_numexpr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0m_bool_arith_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mb_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         result = ne.evaluate(\n\u001b[0m\u001b[0;32m    110\u001b[0m             \u001b[1;34mf\"a_value {op_str} b_value\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mlocal_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"a_value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ma_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"b_value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mb_value\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numexpr\\necompiler.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(ex, local_dict, global_dict, out, order, casting, **kwargs)\u001b[0m\n\u001b[0;32m    832\u001b[0m     \u001b[0m_numexpr_last\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompiled_ex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mevaluate_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcompiled_ex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    835\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def run_experiments():\n",
    "    N_values = [3, 5, 7, 9, 12]\n",
    "    \n",
    "    # Initialize dictionaries to store evaluation results\n",
    "    evaluation_results = {'Prediction Method': [], 'N': [], 'MAE': [], 'Precision': [], 'Recall': [], 'Confusion Matrix': []}\n",
    "\n",
    "    # Loop over each prediction method\n",
    "    for method in range(1, 5):\n",
    "        for N in N_values:\n",
    "            mae_scores = []\n",
    "            precision_scores = []\n",
    "            recall_scores = []\n",
    "            confusion_matrices = []\n",
    "            \n",
    "            # Initialize KFold cross-validation\n",
    "            kf = KFold(n_splits=5, shuffle=True)\n",
    "            \n",
    "            # Iterate over the splits\n",
    "            for train_index, test_index in kf.split(filtered_ratings):\n",
    "                # Split the data into training and testing sets\n",
    "                train_data = filtered_ratings.iloc[train_index]\n",
    "                test_data = filtered_ratings.iloc[test_index]\n",
    "                \n",
    "                # Run predictions and evaluate\n",
    "                mae, precision, recall, confusion_matrix_values = evaluate_predictions(train_data, test_data, N, method)\n",
    "                \n",
    "                mae_scores.append(mae)\n",
    "                precision_scores.append(precision)\n",
    "                recall_scores.append(recall)\n",
    "                confusion_matrices.append(confusion_matrix_values)\n",
    "            \n",
    "            # Calculate average evaluation scores across all runs\n",
    "            avg_mae = np.mean(mae_scores)\n",
    "            avg_precision = np.mean(precision_scores)\n",
    "            avg_recall = np.mean(recall_scores)\n",
    "            \n",
    "            # Calculate confusion matrix across all iterations\n",
    "            confusion_matrix = np.sum(confusion_matrices, axis=0)\n",
    "            \n",
    "            # Store results in the dictionary\n",
    "            evaluation_results['Prediction Method'].append(method)\n",
    "            evaluation_results['N'].append(N)\n",
    "            evaluation_results['MAE'].append(avg_mae)\n",
    "            evaluation_results['Precision'].append(avg_precision)\n",
    "            evaluation_results['Recall'].append(avg_recall)\n",
    "            evaluation_results['Confusion Matrix'].append(confusion_matrix)\n",
    "    \n",
    "    # Convert the dictionary to a DataFrame\n",
    "    results_df = pd.DataFrame(evaluation_results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "def evaluate_predictions(train_data, test_data, N, method):\n",
    "    # Placeholder for evaluation metrics\n",
    "    mae_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    \n",
    "    # Initialize confusion matrix\n",
    "    confusion_matrix_values = np.zeros((2, 2))\n",
    "    \n",
    "    # Loop over each user and movie in the test set\n",
    "    for _, row in test_data.iterrows():\n",
    "        userId = row['userId']\n",
    "        movieId = row['movieId']\n",
    "        \n",
    "        # Call the prediction function\n",
    "        prediction = predict_ratings(train_data, userId, movieId, N, method)\n",
    "            \n",
    "        # Calculate the error\n",
    "        actual_rating = row['rating']\n",
    "        mae = abs(actual_rating - prediction)\n",
    "        \n",
    "        # Append the error to the list of errors\n",
    "        mae_scores.append(mae)\n",
    "        \n",
    "        # Binary classification for precision and recall\n",
    "        binary_actual = 1 if actual_rating >= 3 else 0\n",
    "        binary_prediction = 1 if prediction >= 3 else 0\n",
    "        \n",
    "        precision_scores.append(binary_actual == binary_prediction)\n",
    "        recall_scores.append(binary_actual)\n",
    "        \n",
    "        # Update confusion matrix\n",
    "        confusion_matrix_values[binary_actual, binary_prediction] += 1\n",
    "    \n",
    "    # Calculate MAE\n",
    "    mae = np.mean(mae_scores)\n",
    "    \n",
    "    # Calculate Precision and Recall\n",
    "    precision = precision_score(precision_scores, recall_scores, average='macro')\n",
    "    recall = recall_score(precision_scores, recall_scores, average='macro')\n",
    "    \n",
    "    return mae, precision, recall, confusion_matrix_values\n",
    "\n",
    "\n",
    "# Run the experiments\n",
    "results = run_experiments()\n",
    "\n",
    "# Print the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
